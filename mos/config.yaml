# ==== PATHS ====
DATASET_ROOT: "D:/Subhransu workspace/Dataset/my_kitti_dataset/dataset"
SEQUENCES_TRAIN: ["00","01","02","03","04","05","06","07","09","10"]
SEQUENCE_VAL: "08"

# ==== IO / batching ====
num_workers: 4
batch_size: 6              # reduce a bit if you raise points
max_points: 12288
use_prev: true
n_prev: 3                  
max_prev_points: 80000

#speed knobs
frame_stride: 3        # use every 3rd frame
prev_voxel_size: 0.6   # downsample prev before dmin
dmin_chunk: 4096       # GPU chunk for cdist
# ==== training ====
epochs: 20
bce_burnin_epochs: 2
lr: 1.0e-4
weight_decay: 1.0e-4
class_weight_moving: 300
focal_gamma: 2.0
eval_threshold: 0.81
eval_sweep: false
init_prior)bias: true
prior_scan_batches: 8
# LR schedule + warmup
scheduler: "cosine"        # ["cosine", "none"]
warmup_epochs: 3

# EMA
ema_enable: true
ema_decay: 0.999

# Per-range loss weighting (soft boost for far points)
range_weight:
  enable: true
  alpha: 0.5              # up to +50% weight for far pts
  r0: 20.0                # start boosting after 20m
  r1: 50.0                # reach max boost at 50m+

# ==== augmentation ====
aug:
  jitter_std: 0.01
  flip_prob: 0.5
  rot_limit_deg: 5.0

# ==== logging ====
log_interval: 50
val_interval_epochs: 1

# ==== misc ====
device: "cuda"
random_seed: 42
semantic_kitti_yaml: null

# --- model switch ---
model_name: "bev_unet"   # "tiny_mlp" (old) or "me_unet"

# BEV grid config (meters)
bev:
  voxel_size_xy: 0.20     # BEV cell size (x/y), m
  x_min: -50.0
  x_max:  50.0
  y_min: -50.0
  y_max:  50.0
  base_ch: 32             # BEV UNet width (try 32 → 48 → 64)

# Point feature layout your dataset provides
# points = [x,y,z,intensity,range,(optional norm_dmin when use_prev=True)]
use_prev: true            # if true, we assume a 6th channel: norm_dmin
